{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# U-Net Model\n",
    "In this week's assignment, you'll be using a network architecture called \"U-Net\". The name of this network architecture comes from it's U-like shape when shown in a diagram like this (image from [U-net entry on wikipedia](https://en.wikipedia.org/wiki/U-Net)):\n",
    "\n",
    "<img src=\"images/U-net_example_wikipedia.png\" alt=\"U-net Image\" width=\"600\"/>\n",
    "\n",
    "U-nets are commonly used for image segmentation, which will be your task in the upcoming assignment. You won't actually need to implement U-Net in the assignment, but we wanted to give you an opportunity to gain some familiarity with this architecture here before you use it in the assignment.\n",
    "\n",
    "As you can see from the diagram, this architecture features a series of down-convolutions connected by max-pooling operations, followed by a series of up-convolutions connected by upsampling and concatenation operations. Each of the down-convolutions is also connected directly to the concatenation operations in the upsampling portion of the network. For more detail on the U-Net architecture, have a look at the original [U-Net paper by Ronneberger et al. 2015](https://arxiv.org/abs/1505.04597).\n",
    "\n",
    "In this lab, you'll create a basic U-Net using Keras. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "# from keras.engine import Input, Model\n",
    "from keras.layers import Conv3D, MaxPool3D, UpSampling3D, Activation, BatchNormalization, PReLU\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# set image shape to have the channles in the first dim\n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Conv3DTranspose\n",
    "tensorflow.compat.v1.logging.set_verbosity(tensorflow.compat.v1.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. The \"Depth\" of your U-Net\n",
    "The \"depth\" of your U-Net is equal to the number of down-convolutions you will use. In the image above, the depth is 4 because there are 4 down-convolutions running down the left side including the very bottom of the U.\n",
    "\n",
    "For this exercise, you'll use a U-Net depth of 2, meaning you'll have 2 down-convolutions in your network."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 1.1 Input Layer and its \"Depth\"\n",
    "\n",
    "In this lab and in the assignment, you will be doing 3D image segmentation, which is to say that, in addition to \"height\" and \"width\", your input layer will also have a \"length\". We are deliberately using the word \"length\" instead of \"depth\" here to describe the third spatial dimension of the input so as not to confuse it with the depth of the network as defined above.\n",
    "\n",
    "The shape of the input layer is `(num_channels, height, width, length)`, where `num_channels` you can think of like color channels in an image, `height`, `width` and `length` are just the size of the input.\n",
    "\n",
    "For the assignment, the values will be:\n",
    "- num_channels: 4\n",
    "- height: 160\n",
    "- width: 160\n",
    "- length: 16"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "<KerasTensor: shape=(None, 4, 160, 160, 16) dtype=float32 (created by layer 'input_1')>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define input layer\n",
    "input_layer = Input(shape=(4, 160, 160, 16))\n",
    "input_layer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice that the tensor shape has a '?' as the very first dimension.  This will be the batch size. So the dimensions of the tensor are: (batch_size, num_channels, height, width, length)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Contracting (downward) Path\n",
    "Here you'll start by constructing the downward path in your network (the left side of the U-Net).  The `(height, width, length)` of the input gets smaller as you move down this path, and the number of channels increases.\n",
    "\n",
    "### 2.1 Depth 0\n",
    "\n",
    "By \"depth 0\" here, we're referring to the depth of the first down-convolution in the U-net.\n",
    "\n",
    "The number of filters is specified for each depth and for each layer within that depth.\n",
    "\n",
    "The formula to use for calculating the number of filters is:\n",
    "$$filters_{i} = 32 \\times (2^{i})$$\n",
    "\n",
    "Where $i$ is the current depth.\n",
    "\n",
    "So at depth $i=0$:\n",
    "$$filters_{0} = 32 \\times (2^{0}) = 32$$\n",
    "\n",
    "### 2.2 Layer 0\n",
    "There are two convolutional layers for each depth"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "<KerasTensor: shape=(None, 32, 160, 160, 16) dtype=float32 (created by layer 'conv3d')>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "down_depth0_l0 = Conv3D(filters=32,\n",
    "                        kernel_size=(3, 3, 3),\n",
    "                        padding='same',\n",
    "                        strides=(1, 1, 1))(input_layer)\n",
    "down_depth0_l0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Notice that with 32 filters, the result you get above is a tensor with 32 channels.\n",
    "\n",
    "Run the next cell to add a relu activation to the first convolutional layer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "<KerasTensor: shape=(None, 32, 160, 160, 16) dtype=float32 (created by layer 'activation')>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relu0 = Activation('relu')(down_depth0_l0)\n",
    "relu0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.3 Depth 0, Layer 1\n",
    "For layer 1 of depth 0, the formula for calculating the number of filters is:\n",
    "$$filters_{i} = 32 \\times (2^{i}) \\times 2$$\n",
    "\n",
    "Where $i$ is the current depth.\n",
    "- Notice that the '$\\times~2$' at the end of this expression isn't there for layer 0.\n",
    "\n",
    "\n",
    "So at depth $i=0$ for layer 1:\n",
    "$$filters_{0} = 32 \\times (2^{0}) \\times 2 = 64$$\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<KerasTensor: shape=(None, 64, 160, 160, 16) dtype=float32 (created by layer 'activation_1')>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "down_depth0_l1 = Conv3D(filters=64,\n",
    "                        kernel_size=(3, 3, 3),\n",
    "                        padding='same',\n",
    "                        strides=(1, 1, 1))(down_depth0_l0)\n",
    "down_depth0_l1 = Activation('relu')(down_depth0_l1)\n",
    "down_depth0_l1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2.4 Max pooling\n",
    "Within the U-Net architecture, there is a max pooling operation after each of the down-convolutions (not including the last down-convolution at the bottom of the U). In general, this means you'll add max pooling after each down-convolution up to (but not including) the `depth - 1` down-convolution (since you started counting at 0).\n",
    "\n",
    "For this lab exercise:\n",
    "- The overall depth of the U-Net you're constructing is 2\n",
    "- So the bottom of your U is at a depth index of: $2-1 = 1$.\n",
    "- So far you've only defined the $depth=0$ down-convolutions, so the next thing to do is add max pooling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<KerasTensor: shape=(None, 64, 80, 80, 8) dtype=float32 (created by layer 'max_pooling3d')>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "down_depth0_pool = MaxPool3D(pool_size=(2, 2, 2))(down_depth0_l1)\n",
    "down_depth0_pool"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.4.1 Depth 1, Layer 0\n",
    "\n",
    "At depth 1, layer 0, the formula for calculating the number of filters is:\n",
    "$$filters_{i} = 32 \\times (2^{i})$$\n",
    "\n",
    "Where $i$ is the current depth.\n",
    "\n",
    "So at depth $i=1$:\n",
    "$$filters_{1} = 32 \\times (2^{1}) = 64$$\n",
    "\n",
    "Run the next cell to add a Conv3D layer to your network with relu activation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<KerasTensor: shape=(None, 64, 80, 80, 8) dtype=float32 (created by layer 'activation_2')>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "down_depth1_l0 = Conv3D(filters=64,\n",
    "                        kernel_size=(3, 3, 3),\n",
    "                        padding='same',\n",
    "                        strides=(1, 1, 1))(down_depth0_pool)\n",
    "down_depth1_l0 = Activation('relu')(down_depth1_l0)\n",
    "down_depth1_l0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### 2.4.2 Depth 1,  Layer 1\n",
    "\n",
    "For layer 1 of depth 1 the formula you'll use for number of filters is:\n",
    "$$filters_{i} = 32 \\times (2^{i}) \\times 2$$\n",
    "\n",
    "Where $i$ is the current depth.\n",
    "- Notice that the '$\\times 2$' at the end of this expression isn't there for layer 0.\n",
    "\n",
    "So at depth $i=1$:\n",
    "$$filters_{0} = 32 \\times (2^{1}) \\times 2 = 128$$\n",
    "\n",
    "Run the next cell to add another Conv3D with 128 filters to your network."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "<KerasTensor: shape=(None, 128, 80, 80, 8) dtype=float32 (created by layer 'activation_3')>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "down_depth1_l1 = Conv3D(filters=128,\n",
    "                        kernel_size=(3, 3, 3),\n",
    "                        padding='same',\n",
    "                        strides=(1, 1, 1))(down_depth1_l0)\n",
    "down_depth1_l1 = Activation('relu')(down_depth1_l1)\n",
    "down_depth1_l1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### No max pooling at depth 1 (the bottom of the U)\n",
    "\n",
    "When you get to the \"bottom\" of the U-net, you don't need to apply max pooling after the convolutions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 3. Expanding  (upward) Path\n",
    "\n",
    "Now you'll work on the expanding path of the U-Net, (going up on the right side, when viewing the diagram).  The image's (height, width, length) all get larger in the expanding path.\n",
    "\n",
    "### 3.1 Depth 0, Up Sampling Layer 0\n",
    "\n",
    "You'll use a pool size of (2,2,2) for upsampling.\n",
    "- This is the default value for [tf.keras.layers.UpSampling3D](https://www.tensorflow.org/api_docs/python/tf/keras/layers/UpSampling3D)\n",
    "- As input to the upsampling at depth 1, you'll use the last layer of the downsampling.  In this case, it's the depth 1 layer 1.\n",
    "\n",
    "Run the next cell to add an upsampling operation to your network.\n",
    "Note that you're not adding any activation to this upsampling layer."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}